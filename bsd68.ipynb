{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3000ec3",
   "metadata": {},
   "source": [
    "# BSD68 Dataset Denoising tramite Noise2Void\n",
    "\n",
    "Questo notebook descrive, passo dopo passo, l'addestramento e il testing di una **Rete Neurale U-Net** per la riduzione del rumore sulle immagini del **Dataset BSD68**.  \n",
    "\n",
    "La rete applica l'algoritmo **Noise2Void (N2V)**, la cui implementazione è resa disponibile dalla libreria **CAREamics**, permettendo di ottenere immagini pulite **senza necessità di Ground Truth**.\n",
    "\n",
    "L'obiettivo di questa attività è:\n",
    "\n",
    "- Comprendere le potenzialità delle **Deep Neural Networks** nell'ambito del denoising.  \n",
    "- Confrontare i risultati di N2V con quelli ottenuti tramite metodi di denoising tradizionali.  \n",
    "- Approfondire il funzionamento e le caratteristiche dell'algoritmo **Noise2Void**.\n",
    "\n",
    "## Il Dataset BSD68\n",
    "\n",
    "Il **BSD68** è un dataset di riferimento per la ricerca nel denoising. Le sue caratteristiche principali sono:\n",
    "\n",
    "- Contiene immagini **in bianco e nero** di scene naturali, animali, persone e oggetti.  \n",
    "- Le immagini sono state **artificialmente corrotte da rumore** di diversa intensità.  \n",
    "- Sono disponibili le **Ground Truth**, ossia le immagini originali pulite, utili per valutare la qualità del denoising.  \n",
    "\n",
    "Grazie alla presenza di Ground Truth, possiamo **valutare in modo oggettivo** le capacità dell'algoritmo **Noise2Void**, osservando come riesca a recuperare dettagli significativi pur lavorando su immagini rumorose.\n",
    "\n",
    "\n",
    "Il BSD68 permette di testare Noise2Void su soggetti facilmente riconoscibili, offrendo una **valutazione visiva immediata** e quantitativa delle prestazioni dell'algoritmo.  \n",
    "Questo lo rende ideale sia per esperimenti didattici sia per benchmarking nel contesto della ricerca scientifica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef08320",
   "metadata": {},
   "source": [
    "# Download del Dataset\n",
    "\n",
    "Il dataset viene scaricato utilizzando il **Portfolio** reso disponibile dalla libreria **CAREamics**.  \n",
    "Contiene più di **3.000 immagini** di formati e soggetti differenti, salvate in formato **.TIFF** con una codifica speciale compatibile con **ImageJ**.\n",
    "\n",
    "\n",
    "## Struttura del Dataset\n",
    "\n",
    "Le immagini sono già suddivise in **4 categorie principali**:\n",
    "\n",
    "1. **Dati di Training** – 3168 immagini  \n",
    "   Consentono alla rete neurale di **apprendere i parametri ottimali** durante l'addestramento.\n",
    "\n",
    "2. **Dati di Validation** – 4 immagini  \n",
    "   Permettono di **monitorare l’andamento dell’addestramento**, evitando il rischio di overfitting.\n",
    "\n",
    "3. **Dati di Testing** – 68 immagini  \n",
    "   Utilizzati **solo a fine addestramento** per valutare le prestazioni finali del modello.\n",
    "\n",
    "4. **Ground Truth dei Dati di Testing** – 68 immagini  \n",
    "   Contengono le versioni **pulite** dei dati di testing, necessarie per il **confronto quantitativo e visivo** dei risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from careamics import CAREamist\n",
    "from careamics.config import create_n2v_configuration\n",
    "from careamics.utils.metrics import scale_invariant_psnr\n",
    "\n",
    "sys.path.append('library')\n",
    "\n",
    "import library.dataset as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48691aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downlaod the Dataset\n",
    "root_path = Path(\"notebooks/data/bsd68\")\n",
    "dataset.load_bsd68_dataset(root_path)\n",
    "\n",
    "# The Dataset is already split into Training, Validation, Testing and Grand Truths\n",
    "data_path = Path(root_path / \"denoising-N2V_BSD68.unzip/BSD68_reproducibility_data\")\n",
    "train_path = data_path / \"train\"\n",
    "val_path = data_path / \"val\"\n",
    "test_path = data_path / \"test\" / \"images\"\n",
    "gt_path = data_path / \"test\" / \"gt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493c024",
   "metadata": {},
   "source": [
    "## Visualizzazione del Dataset\n",
    "\n",
    "Per comprendere meglio le caratteristiche del BSD68 Dataset, visualizziamo alcune immagini a scopo illustrativo.\n",
    "\n",
    "Si può notare che alcune immagini presentano trasformazioni come **simmetrie, rotazioni e flip**, tipiche delle tecniche di **data augmentation** utilizzate durante l’addestramento delle reti U-Net.  \n",
    "Queste trasformazioni aiutano la Rete Neurale a diventare più **robusta**, permettendole di gestire meglio situazioni diverse da quelle presenti nel dataset originale.\n",
    "\n",
    "Di seguito mostriamo alcune immagini scelte casualmente dal Dataset, evidenziando le varie tipologie di soggetti e di rumore applicato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc80d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tifffile.imread(next(iter(train_path.rglob(\"*.tiff\")))) # 3168 images\n",
    "val_images = tifffile.imread(next(iter(val_path.rglob(\"*.tiff\"))))\n",
    "starting_index = 8 #Change this to show different images\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\n",
    "\n",
    "for ax, idx in zip(axes.flat, range(starting_index, starting_index + 16)): #Couples the axes with the indexes\n",
    "    ax.imshow(train_images[idx], cmap=\"gray\")\n",
    "    ax.set_title(f\"Training Image {idx}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46784830",
   "metadata": {},
   "source": [
    "## Creazione della Configurazione di Training\n",
    "\n",
    "Prima di procedere all'addestramento della rete, è necessario creare un oggetto di **configurazione** che definisca sia l'architettura della rete sia i parametri di training.\n",
    "\n",
    "I parametri principali da considerare sono:\n",
    "\n",
    "- **batch_size**: il numero di immagini elaborate in parallelo durante ogni step di addestramento.  \n",
    "  Valori più alti richiedono più memoria GPU, ma possono velocizzare l’addestramento.\n",
    "- **num_epochs**: il numero di volte in cui l’intero dataset viene utilizzato per aggiornare i pesi della rete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_n2v_configuration(\n",
    "    experiment_name=\"bsd68_n2v\",\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"SYX\",\n",
    "    patch_size=(64, 64),\n",
    "    batch_size=64,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9051b81",
   "metadata": {},
   "source": [
    "## Addestramento del Modello\n",
    "L'addestramento del modello avviene tramite la creazione di un oggetto **CAREamist**, utilizzando la configurazione definita precedentemente.\n",
    "\n",
    "### Come funziona:\n",
    "\n",
    "- Il metodo `.train()` richiede i **percorsi alle immagini di Training e Validation**.\n",
    "- Durante l'addestramento, la rete apprende a **ridurre il rumore** dalle immagini, aggiornando i propri pesi.\n",
    "- È possibile osservare in tempo reale alcuni parametri di performance, come:\n",
    "  - **Loss**: misura l'errore tra le predizioni del modello e i valori target.\n",
    "  - **PSNR (Peak Signal-to-Noise Ratio)**: indica la qualità delle immagini denoised rispetto alla ground truth (se disponibile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb125e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before proceding, make sure your GPU is available to PyTorch or the training will be very slow\n",
    "\n",
    "careamist = CAREamist(source=config, work_dir=\"notebooks/models/bsd68\")\n",
    "\n",
    "# train model\n",
    "print(f\"Training starting now...\")\n",
    "careamist.train(train_source=train_path, val_source=val_path)\n",
    "print(\"Training ended!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b4da5",
   "metadata": {},
   "source": [
    "## Generate Predictions\n",
    "\n",
    "Terminato l'addestramento, possiamo osservare il comportamento del modello chiedendogli di **predire le immagini pulite** a partire dai campioni rumorosi del set **Testing**.\n",
    "\n",
    "### Procedura:\n",
    "\n",
    "- Utilizziamo il metodo `.predict` del modello CAREamist.\n",
    "- Il modello impiega l'**ultimo checkpoint salvato** durante il training.\n",
    "- Le predizioni vengono effettuate su tutte le **68 immagini** del dataset BSD68 Testing.\n",
    "\n",
    "Questo passaggio permette di ottenere le immagini denoised, che saranno poi confrontate con le Ground Truth per valutare l’efficacia dell’algoritmo Noise2Void.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f963da",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"notebooks/predictions/bsd68/predictions.tiff\"\n",
    "\n",
    "prediction = careamist.predict(\n",
    "    source=test_path,\n",
    "    axes=\"YX\",\n",
    "    tile_size=(128, 128),\n",
    "    tile_overlap=(48, 48),\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9eaf4c",
   "metadata": {},
   "source": [
    "## Visualizzazione delle Predizioni\n",
    "\n",
    "A questo punto possiamo mostrare i risultati delle predizioni del modello.\n",
    "\n",
    "### Procedura:\n",
    "\n",
    "- Selezioniamo **n immagini casuali** dal dataset di test.\n",
    "- Visualizziamo:\n",
    "  - **Input rumoroso**\n",
    "  - **Predizione della rete (denoised)**\n",
    "  - **Ground Truth**, quando disponibile, per un confronto diretto.\n",
    "  \n",
    "Questo confronto visivo consente di valutare in modo intuitivo:\n",
    "\n",
    "- La capacità dell'algoritmo **Noise2Void (N2V)** di rimuovere il rumore.\n",
    "- I limiti del modello in determinate situazioni o tipologie di rumore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a976082",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "test_images = [tifffile.imread(f) for f in sorted(test_path.glob(\"*.tiff\"))]\n",
    "ground_truth_images = [tifffile.imread(f) for f in sorted(gt_path.glob(\"*.tiff\"))]\n",
    "\n",
    "random_indexes = np.random.choice(range(len(test_images)), n)\n",
    "\n",
    "fig, ax = plt.subplots(4, 3, figsize=(15, 15))\n",
    "for a, i in zip(range(n), random_indexes):\n",
    "    ax[a, 0].imshow(test_images[i], cmap=\"gray\")\n",
    "    ax[a, 0].set_title(f\"Noisy {i}\")\n",
    "    ax[a, 1].imshow(prediction[i].squeeze(), cmap=\"gray\")\n",
    "    ax[a, 1].set_title(f\"Prediction {i}\")\n",
    "    ax[a, 2].imshow(ground_truth_images[i], cmap=\"gray\")\n",
    "    ax[a, 2].set_title(f\"Grand Truth {i}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
